{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl\n",
    "import createGraph\n",
    "from importlib import reload\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import architecture\n",
    "import training_loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('duke_vital_model_imputed.csv')\n",
    "X = df.drop(labels=[\"PostCond\"], axis=1).to_numpy\n",
    "y = df[\"PostCond\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values - process will be made a little more complex later when we impute train and test vals separately; for now we can do it like this\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_graphs - figure out how to do this\n",
    "g, y, node_batches = load_graphs(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/val sets and test sets\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=42)\n",
    "indices = skf.split(np.zeros(len(y)), y)\n",
    "train_val_mask = dict()\n",
    "test_mask = dict()\n",
    "cnt = 0\n",
    "for train_i, test_i in indices:\n",
    "    train_val_mask[cnt] = train_i\n",
    "    test_mask[cnt] = test_i\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/val sets into train sets and val sets\n",
    "train_mask = dict()\n",
    "val_mask = dict()\n",
    "\n",
    "for i in range(0, 10):\n",
    "    train_mask[i], val_mask[i] = train_test_split(train_val_mask[i], y[train_val_mask[i]], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = architecture.GCN(g['feats'].shape(-1), 30, 30)\n",
    "\n",
    "training_loop.train(g=g, node_batches=node_batches, labels=y, train_mask=train_mask[0], val_mask=val_mask[0], validate=True, test=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09f61af4f65d4634c17b8a51ddf1eb855b373cdae4e53182aef1e6aee687f5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
