{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torchx\n",
    "\n",
    "from torchx import specs\n",
    "from torchx.components import utils\n",
    "\n",
    "\n",
    "def trainer(\n",
    "    log_path: str,\n",
    "    hidden_size_1: int,\n",
    "    hidden_size_2: int,\n",
    "    learning_rate: float,\n",
    "    epochs: int,\n",
    "    dropout: float,\n",
    "    batch_size: int,\n",
    "    trial_idx: int = -1,\n",
    ") -> specs.AppDef:\n",
    "\n",
    "    # define the log path so we can pass it to the TorchX AppDef\n",
    "    if trial_idx >= 0:\n",
    "        log_path = Path(log_path).joinpath(str(trial_idx)).absolute().as_posix()\n",
    "\n",
    "    return utils.python(\n",
    "        # command line args to the training script\n",
    "        \"--log_path\",\n",
    "        log_path,\n",
    "        \"--hidden_size_1\",\n",
    "        str(hidden_size_1),\n",
    "        \"--hidden_size_2\",\n",
    "        str(hidden_size_2),\n",
    "        \"--learning_rate\",\n",
    "        str(learning_rate),\n",
    "        \"--epochs\",\n",
    "        str(epochs),\n",
    "        \"--dropout\",\n",
    "        str(dropout),\n",
    "        \"--batch_size\",\n",
    "        str(batch_size),\n",
    "        # other config options\n",
    "        name=\"trainer\",\n",
    "        script=\"mnist_train_nas.py\",\n",
    "        image=torchx.version.TORCHX_IMAGE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from ax.runners.torchx import TorchXRunner\n",
    "\n",
    "# Make a temporary dir to log our results into\n",
    "log_dir = tempfile.mkdtemp()\n",
    "\n",
    "ax_runner = TorchXRunner(\n",
    "    tracker_base=\"/tmp/\",\n",
    "    component=trainer,\n",
    "    # NOTE: To launch this job on a cluster instead of locally you can\n",
    "    # specify a different scheduler and adjust args appropriately.\n",
    "    scheduler=\"local_cwd\",\n",
    "    component_const_params={\"log_path\": log_dir},\n",
    "    cfg={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.core import (\n",
    "    ChoiceParameter,\n",
    "    ParameterType,\n",
    "    RangeParameter,\n",
    "    SearchSpace,\n",
    ")\n",
    "\n",
    "parameters = [\n",
    "    # NOTE: In a real-world setting, hidden_size_1 and hidden_size_2\n",
    "    # should probably be powers of 2, but in our simple example this\n",
    "    # would mean that num_params can't take on that many values, which\n",
    "    # in turn makes the Pareto frontier look pretty weird.\n",
    "    RangeParameter(\n",
    "        name=\"hidden_size_1\",\n",
    "        lower=16,\n",
    "        upper=128,\n",
    "        parameter_type=ParameterType.INT,\n",
    "        log_scale=True,\n",
    "    ),\n",
    "    RangeParameter(\n",
    "        name=\"hidden_size_2\",\n",
    "        lower=16,\n",
    "        upper=128,\n",
    "        parameter_type=ParameterType.INT,\n",
    "        log_scale=True,\n",
    "    ),\n",
    "    RangeParameter(\n",
    "        name=\"learning_rate\",\n",
    "        lower=1e-4,\n",
    "        upper=1e-2,\n",
    "        parameter_type=ParameterType.FLOAT,\n",
    "        log_scale=True,\n",
    "    ),\n",
    "    RangeParameter(\n",
    "        name=\"epochs\",\n",
    "        lower=1,\n",
    "        upper=4,\n",
    "        parameter_type=ParameterType.INT,\n",
    "    ),\n",
    "    RangeParameter(\n",
    "        name=\"dropout\",\n",
    "        lower=0.0,\n",
    "        upper=0.5,\n",
    "        parameter_type=ParameterType.FLOAT,\n",
    "    ),\n",
    "    ChoiceParameter(  # NOTE: ChoiceParameters don't require log-scale\n",
    "        name=\"batch_size\",\n",
    "        values=[32, 64, 128, 256],\n",
    "        parameter_type=ParameterType.INT,\n",
    "        is_ordered=True,\n",
    "        sort_values=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "search_space = SearchSpace(\n",
    "    parameters=parameters,\n",
    "    # NOTE: In practice, it may make sense to add a constraint\n",
    "    # hidden_size_2 <= hidden_size_1\n",
    "    parameter_constraints=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.metrics.tensorboard import TensorboardCurveMetric\n",
    "\n",
    "\n",
    "class MyTensorboardMetric(TensorboardCurveMetric):\n",
    "\n",
    "    # NOTE: We need to tell the new Tensorboard metric how to get the id /\n",
    "    # file handle for the tensorboard logs from a trial. In this case\n",
    "    # our convention is to just save a separate file per trial in\n",
    "    # the pre-specified log dir.\n",
    "    @classmethod\n",
    "    def get_ids_from_trials(cls, trials):\n",
    "        return {\n",
    "            trial.index: Path(log_dir).joinpath(str(trial.index)).as_posix()\n",
    "            for trial in trials\n",
    "        }\n",
    "\n",
    "    # This indicates whether the metric is queryable while the trial is\n",
    "    # still running. We don't use this in the current tutorial, but Ax\n",
    "    # utilizes this to implement trial-level early-stopping functionality.\n",
    "    @classmethod\n",
    "    def is_available_while_running(cls):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = MyTensorboardMetric(\n",
    "    name=\"val_acc\",\n",
    "    curve_name=\"val_acc\",\n",
    "    lower_is_better=False,\n",
    ")\n",
    "model_num_params = MyTensorboardMetric(\n",
    "    name=\"num_params\",\n",
    "    curve_name=\"num_params\",\n",
    "    lower_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.core import MultiObjective, Objective, ObjectiveThreshold\n",
    "from ax.core.optimization_config import MultiObjectiveOptimizationConfig\n",
    "\n",
    "\n",
    "opt_config = MultiObjectiveOptimizationConfig(\n",
    "    objective=MultiObjective(\n",
    "        objectives=[\n",
    "            Objective(metric=val_acc, minimize=False),\n",
    "            Objective(metric=model_num_params, minimize=True),\n",
    "        ],\n",
    "    ),\n",
    "    objective_thresholds=[\n",
    "        ObjectiveThreshold(metric=val_acc, bound=0.94, relative=False),\n",
    "        ObjectiveThreshold(metric=model_num_params, bound=80_000, relative=False),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.core import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=\"torchx_mnist\",\n",
    "    search_space=search_space,\n",
    "    optimization_config=opt_config,\n",
    "    runner=ax_runner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trials = 48  # total evaluation budget\n",
    "\n",
    "from ax.modelbridge.dispatch_utils import choose_generation_strategy\n",
    "\n",
    "gs = choose_generation_strategy(\n",
    "    search_space=experiment.search_space,\n",
    "    optimization_config=experiment.optimization_config,\n",
    "    num_trials=total_trials,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.scheduler import Scheduler, SchedulerOptions\n",
    "\n",
    "scheduler = Scheduler(\n",
    "    experiment=experiment,\n",
    "    generation_strategy=gs,\n",
    "    options=SchedulerOptions(\n",
    "        total_trials=total_trials, max_pending_trials=4\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.run_all_trials()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.utils.report_utils import exp_to_df\n",
    "\n",
    "df = exp_to_df(experiment)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.utils.report_utils import _pareto_frontier_scatter_2d_plotly\n",
    "\n",
    "_pareto_frontier_scatter_2d_plotly(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.modelbridge.cross_validation import compute_diagnostics, cross_validate\n",
    "from ax.plot.diagnostic import interact_cross_validation_plotly\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "\n",
    "cv = cross_validate(model=gs.model)  # The surrogate model is stored on the GenerationStrategy\n",
    "compute_diagnostics(cv)\n",
    "\n",
    "interact_cross_validation_plotly(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.plot.contour import interact_contour_plotly\n",
    "\n",
    "interact_contour_plotly(model=gs.model, metric_name=\"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_contour_plotly(model=gs.model, metric_name=\"num_params\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09f61af4f65d4634c17b8a51ddf1eb855b373cdae4e53182aef1e6aee687f5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
